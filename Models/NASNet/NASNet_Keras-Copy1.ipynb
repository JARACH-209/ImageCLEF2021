{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "# from tensorflow_addons.optimizers import CyclicalLearningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NASNet_Transfer_Mask_NOMEAN_1_CORONA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "base = os.path.join('Datasets', 'ImageCLEF', 'Coronal_Slice_Masks_300')\n",
    "\n",
    "train_dir = os.path.join(home, base, 'train')\n",
    "test_dir = os.path.join(home, base, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121203 images belonging to 5 classes.\n",
      "Found 29748 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "shuffle = True\n",
    "inp_shp = (224, 224)\n",
    "train_batch_size, val_batch_size = 16, 64\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#                     rescale=1./255,\n",
    "                    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=inp_shp,\n",
    "        batch_size=train_batch_size,\n",
    "        seed=seed,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=shuffle\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=inp_shp,\n",
    "        batch_size=val_batch_size,\n",
    "        seed=seed,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "MobileNet = tf.keras.applications.MobileNet(\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.1,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "MobileNet.trainable = False\n",
    "MobileNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONv/FC -> BatchNorm -> ReLU(or other activation) -> Dropout -> CONV/FC -> ...\n",
    "\n",
    "def get_model(base_model, input_shape):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = keras.applications.nasnet.preprocess_input(inputs)\n",
    "    y = base_model(x, training=False)\n",
    "    \n",
    "    z = layers.MaxPooling2D(pool_size=(3, 3))(y)\n",
    "    \n",
    "    x = layers.Conv2D(256, (2, 2), activation=None)(y)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (2, 2), activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=3)([x, z])\n",
    "#     x = layers.Conv2D(32, (3, 3), activation=None)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(units=96, activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    y = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "    x = layers.Dense(units=64, activation=None)(y)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    x = layers.Dropout(rate=0.25)(x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([x, y])\n",
    "    \n",
    "    x = layers.Dense(units=5, activation=None)(x)\n",
    "    output = layers.Softmax()(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name=f'{model_name}')\n",
    "    \n",
    "    return model\n",
    "#     model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NASNet_Transfer_Mask_NOMEAN_1_CORONA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv_6 (TensorFl [(None, 224, 224, 3) 0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_6 (TensorFlowOp [(None, 224, 224, 3) 0           tf_op_layer_truediv_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mobilenet_1.00_224 (Model)      (None, 7, 7, 1024)   3228864     tf_op_layer_sub_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 6, 6, 128)    524416      mobilenet_1.00_224[7][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 6, 6, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 6, 6, 128)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 5, 5, 128)    65664       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 5, 5, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 5, 5, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 2, 2, 128)    0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 1024)   0           mobilenet_1.00_224[7][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2, 2, 1152)   0           max_pooling2d_12[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 4608)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           294976      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64)           256         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 64)           0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           1040        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16)           64          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 16)           0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16)           0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 80)           0           dropout_9[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 5)            405         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_4 (Softmax)             (None, 5)            0           dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,116,709\n",
      "Trainable params: 887,173\n",
      "Non-trainable params: 3,229,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(MobileNet, input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 5e-3\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=initial_learning_rate),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 197 steps, validate for 58 steps\n",
      "Epoch 1/20\n",
      "197/197 [==============================] - 39s 197ms/step - loss: 1.4589 - accuracy: 0.4337 - val_loss: 3.6621 - val_accuracy: 0.4502\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - 53s 270ms/step - loss: 1.3482 - accuracy: 0.4803 - val_loss: 1.5597 - val_accuracy: 0.4502\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - 53s 270ms/step - loss: 1.3167 - accuracy: 0.4860 - val_loss: 1.4599 - val_accuracy: 0.4502\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3152 - accuracy: 0.4816 - val_loss: 1.4666 - val_accuracy: 0.4502\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.2936 - accuracy: 0.4937 - val_loss: 1.4711 - val_accuracy: 0.4502\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.2958 - accuracy: 0.4886 - val_loss: 1.4720 - val_accuracy: 0.4502\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3062 - accuracy: 0.4794 - val_loss: 1.4704 - val_accuracy: 0.4502\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3021 - accuracy: 0.4921 - val_loss: 1.4683 - val_accuracy: 0.4502\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.3114 - accuracy: 0.4908 - val_loss: 1.4715 - val_accuracy: 0.4502\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.2806 - accuracy: 0.4860 - val_loss: 1.4686 - val_accuracy: 0.4502\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.3122 - accuracy: 0.4749 - val_loss: 1.4702 - val_accuracy: 0.4502\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.3159 - accuracy: 0.4768 - val_loss: 1.4701 - val_accuracy: 0.4502\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.2918 - accuracy: 0.4879 - val_loss: 1.4710 - val_accuracy: 0.4502\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3108 - accuracy: 0.4806 - val_loss: 1.4720 - val_accuracy: 0.4502\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3000 - accuracy: 0.4924 - val_loss: 1.4721 - val_accuracy: 0.4502\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - 53s 269ms/step - loss: 1.2935 - accuracy: 0.4886 - val_loss: 1.4698 - val_accuracy: 0.4502\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - 53s 269ms/step - loss: 1.2999 - accuracy: 0.4873 - val_loss: 1.4687 - val_accuracy: 0.4502\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.3130 - accuracy: 0.4810 - val_loss: 1.4699 - val_accuracy: 0.4502\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - 53s 268ms/step - loss: 1.3008 - accuracy: 0.4883 - val_loss: 1.4674 - val_accuracy: 0.4502\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - 53s 267ms/step - loss: 1.3001 - accuracy: 0.4921 - val_loss: 1.4688 - val_accuracy: 0.4502\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    f\"{model_name}.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8)\n",
    "\n",
    "clr_triangular = CyclicLR(\n",
    "        mode='triangular2',\n",
    "        base_lr=1e-8,\n",
    "        max_lr=1e-3,\n",
    "        step_size=45\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=20,\n",
    "            steps_per_epoch=197,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=58,\n",
    "            shuffle=False,\n",
    "            callbacks=[checkpoint_cb, clr_triangular]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ffd11596e381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = keras.models.load_model('NASNet_Transfer_Mask_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{model_name}_history.pkl', 'wb') as fh:\n",
    "    pickle.dump(history.history, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
