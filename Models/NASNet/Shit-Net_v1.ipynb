{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'SHIT-Net_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "base = os.path.join('Datasets', 'ImageCLEF', 'Coronal_Slice_Masks_300')\n",
    "\n",
    "train_dir = os.path.join(home, base, 'train')\n",
    "test_dir = os.path.join(home, base, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121203 images belonging to 5 classes.\n",
      "Found 29748 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "shuffle = True\n",
    "#inp_shp = (331, 331)\n",
    "inp_shp = (224,224)\n",
    "train_batch_size, val_batch_size = 16, 64\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=inp_shp,\n",
    "        batch_size=train_batch_size,\n",
    "        seed=seed,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=shuffle\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=inp_shp,\n",
    "        batch_size=val_batch_size,\n",
    "        seed=seed,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        shuffle=shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 331, 331, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 166, 166, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 166, 166, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 166, 166, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 166, 166, 64) 18496       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 166, 166, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 166, 166, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 166, 166, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 166, 166, 128 8896        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 166, 166, 128 512         separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 166, 166, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 166, 166, 128 17664       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 166, 166, 128 512         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 83, 83, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 83, 83, 128)  8320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 83, 83, 128)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 83, 83, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 83, 83, 256)  34176       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 83, 83, 256)  1024        separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 83, 83, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 83, 83, 256)  68096       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 83, 83, 256)  1024        separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 42, 42, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 42, 42, 256)  33024       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 42, 42, 256)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 42, 42, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 42, 42, 512)  133888      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 42, 42, 512)  2048        separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 42, 42, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 42, 42, 512)  267264      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 42, 42, 512)  2048        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 21, 21, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 21, 21, 512)  131584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 21, 21, 512)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 21, 21, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 21, 21, 728)  378072      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 21, 21, 728)  2912        separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 21, 21, 728)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 21, 21, 728)  537264      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 21, 21, 728)  2912        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 728)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 728)  373464      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 11, 11, 728)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 11, 11, 1024) 753048      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 1024) 4096        separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 1024) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            5125        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,786,749\n",
      "Trainable params: 2,778,013\n",
      "Non-trainable params: 8,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (331, 331,3)\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=input_shape, num_classes=5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "from tensorflow_addons.metrics import CohenKappa\n",
    "model.compile(\n",
    "    optimizer=\"Adam\", \n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3743 steps, validate for 1 steps\n",
      "Epoch 1/5\n",
      " 845/3743 [=====>........................] - ETA: 24:00 - loss: 1.3736 - accuracy: 0.4551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c1ecbc4fe14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             shuffle=False)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#             callbacks=[checkpoint_cb, early_stopping_cb]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    f\"{model_name}.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=64)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=5,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=1,\n",
    "            shuffle=False)\n",
    "#             callbacks=[checkpoint_cb, early_stopping_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)\n",
    "ResNet50 = tf.keras.applications.ResNet50V2(\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None\n",
    ")\n",
    "ResNet50.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(base_model, input_shape):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = keras.applications.nasnet.preprocess_input(inputs)\n",
    "    y = base_model(x, training=False)\n",
    "    \n",
    "    z = layers.MaxPooling2D(pool_size=(3, 3))(y)\n",
    "    \n",
    "    x = layers.Conv2D(128, (2, 2), activation=None)(y)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (2, 2), activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=3)([x, z])\n",
    "#     x = layers.Conv2D(32, (3, 3), activation=None)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "#     x = layers.Dropout(rate=0.5)(x)\n",
    "#     x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(units=64, activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    y = layers.Dropout(rate=0.25)(x)\n",
    "\n",
    "    x = layers.Dense(units=16, activation=None)(y)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.1)(x)\n",
    "    x = layers.Dropout(rate=0.25)(x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([x, y])\n",
    "    \n",
    "    x = layers.Dense(units=5, activation=None)(x)\n",
    "    output = layers.Softmax()(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name=f'{model_name}')\n",
    "    \n",
    "    return model\n",
    "#     model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RestNet50-V2_Coronal_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv_1 (TensorFl [(None, 224, 224, 3) 0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_1 (TensorFlowOp [(None, 224, 224, 3) 0           tf_op_layer_truediv_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "resnet50v2 (Model)              (None, 7, 7, 2048)   23564800    tf_op_layer_sub_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 6, 6, 128)    1048704     resnet50v2[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 128)    512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 6, 6, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 5, 256)    131328      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5, 5, 256)    1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 5, 5, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 256)    0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 2, 2, 2048)   0           resnet50v2[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 2, 2304)   0           max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9216)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           589888      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 64)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           1040        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16)           64          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 16)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           dropout_3[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            405         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 5)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,338,021\n",
      "Trainable params: 1,772,293\n",
      "Non-trainable params: 23,565,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(ResNet50, input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 591 steps, validate for 250 steps\n",
      "591/591 [==============================] - 128s 217ms/step - loss: 1.3040 - accuracy: 0.4748 - val_loss: 8.7008 - val_accuracy: 0.4549\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8)\n",
    "\n",
    "model_name = \"RestNet50-V2_Coronal_SkipCon_v3\"\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    f\"{model_name}.h5\", save_best_only=True\n",
    ")\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=591,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=250,\n",
    "            shuffle=False,\n",
    "            callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_res = (224, 224)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Lambda(lambda image: tf.image.resize(image, to_res)))\n",
    "model.add(res_model)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 46 steps, validate for 1 steps\n",
      "Epoch 1/64\n",
      "46/46 [==============================] - 17s 361ms/step - loss: 1.3224 - accuracy: 0.4665 - val_loss: 1.3711 - val_accuracy: 0.4844\n",
      "Epoch 2/64\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 1.3398 - accuracy: 0.4542 - val_loss: 1.3687 - val_accuracy: 0.4844\n",
      "Epoch 3/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3234 - accuracy: 0.4501 - val_loss: 1.3694 - val_accuracy: 0.4844\n",
      "Epoch 4/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.3146 - accuracy: 0.4624 - val_loss: 1.3704 - val_accuracy: 0.4844\n",
      "Epoch 5/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.3190 - accuracy: 0.4788 - val_loss: 1.3719 - val_accuracy: 0.4844\n",
      "Epoch 6/64\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 1.3222 - accuracy: 0.4651 - val_loss: 1.3705 - val_accuracy: 0.4844\n",
      "Epoch 7/64\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 1.3390 - accuracy: 0.4460 - val_loss: 1.3690 - val_accuracy: 0.4844\n",
      "Epoch 8/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3256 - accuracy: 0.4692 - val_loss: 1.3694 - val_accuracy: 0.4844\n",
      "Epoch 9/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3376 - accuracy: 0.4692 - val_loss: 1.3685 - val_accuracy: 0.4844\n",
      "Epoch 10/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3213 - accuracy: 0.4679 - val_loss: 1.3696 - val_accuracy: 0.4844\n",
      "Epoch 11/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3106 - accuracy: 0.4911 - val_loss: 1.3696 - val_accuracy: 0.4844\n",
      "Epoch 12/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3167 - accuracy: 0.4624 - val_loss: 1.3703 - val_accuracy: 0.4844\n",
      "Epoch 13/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3166 - accuracy: 0.4542 - val_loss: 1.3705 - val_accuracy: 0.4844\n",
      "Epoch 14/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3191 - accuracy: 0.4774 - val_loss: 1.3712 - val_accuracy: 0.4844\n",
      "Epoch 15/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.3143 - accuracy: 0.4637 - val_loss: 1.3708 - val_accuracy: 0.4844\n",
      "Epoch 16/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3111 - accuracy: 0.4733 - val_loss: 1.3690 - val_accuracy: 0.4844\n",
      "Epoch 17/64\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 1.3279 - accuracy: 0.4651 - val_loss: 1.3694 - val_accuracy: 0.4844\n",
      "Epoch 18/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3081 - accuracy: 0.4706 - val_loss: 1.3714 - val_accuracy: 0.4844\n",
      "Epoch 19/64\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 1.3158 - accuracy: 0.4596 - val_loss: 1.3714 - val_accuracy: 0.4844\n",
      "Epoch 20/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3133 - accuracy: 0.4651 - val_loss: 1.3703 - val_accuracy: 0.4844\n",
      "Epoch 21/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3266 - accuracy: 0.4651 - val_loss: 1.3709 - val_accuracy: 0.4844\n",
      "Epoch 22/64\n",
      "46/46 [==============================] - 8s 181ms/step - loss: 1.3056 - accuracy: 0.4747 - val_loss: 1.3699 - val_accuracy: 0.4844\n",
      "Epoch 23/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3219 - accuracy: 0.4665 - val_loss: 1.3707 - val_accuracy: 0.4844\n",
      "Epoch 24/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3316 - accuracy: 0.4637 - val_loss: 1.3706 - val_accuracy: 0.4844\n",
      "Epoch 25/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2931 - accuracy: 0.4774 - val_loss: 1.3706 - val_accuracy: 0.4844\n",
      "Epoch 26/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.3262 - accuracy: 0.4583 - val_loss: 1.3703 - val_accuracy: 0.4844\n",
      "Epoch 27/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3247 - accuracy: 0.4583 - val_loss: 1.3710 - val_accuracy: 0.4844\n",
      "Epoch 28/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3104 - accuracy: 0.4542 - val_loss: 1.3717 - val_accuracy: 0.4844\n",
      "Epoch 29/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3215 - accuracy: 0.4774 - val_loss: 1.3710 - val_accuracy: 0.4844\n",
      "Epoch 30/64\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 1.2966 - accuracy: 0.4884 - val_loss: 1.3709 - val_accuracy: 0.4844\n",
      "Epoch 31/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3057 - accuracy: 0.4610 - val_loss: 1.3713 - val_accuracy: 0.4844\n",
      "Epoch 32/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3116 - accuracy: 0.4596 - val_loss: 1.3718 - val_accuracy: 0.4844\n",
      "Epoch 33/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.3165 - accuracy: 0.4364 - val_loss: 1.3720 - val_accuracy: 0.4844\n",
      "Epoch 34/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3209 - accuracy: 0.4815 - val_loss: 1.3736 - val_accuracy: 0.4844\n",
      "Epoch 35/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3175 - accuracy: 0.4692 - val_loss: 1.3730 - val_accuracy: 0.4844\n",
      "Epoch 36/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3114 - accuracy: 0.4624 - val_loss: 1.3712 - val_accuracy: 0.4844\n",
      "Epoch 37/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.2891 - accuracy: 0.4802 - val_loss: 1.3716 - val_accuracy: 0.4844\n",
      "Epoch 38/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.2869 - accuracy: 0.4679 - val_loss: 1.3725 - val_accuracy: 0.4844\n",
      "Epoch 39/64\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 1.2980 - accuracy: 0.4555 - val_loss: 1.3717 - val_accuracy: 0.4844\n",
      "Epoch 40/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.2887 - accuracy: 0.4624 - val_loss: 1.3721 - val_accuracy: 0.4844\n",
      "Epoch 41/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.2889 - accuracy: 0.4774 - val_loss: 1.3737 - val_accuracy: 0.4844\n",
      "Epoch 42/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3004 - accuracy: 0.4815 - val_loss: 1.3755 - val_accuracy: 0.4844\n",
      "Epoch 43/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2936 - accuracy: 0.4747 - val_loss: 1.3739 - val_accuracy: 0.4844\n",
      "Epoch 44/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.2991 - accuracy: 0.4747 - val_loss: 1.3742 - val_accuracy: 0.4844\n",
      "Epoch 45/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.2975 - accuracy: 0.4610 - val_loss: 1.3723 - val_accuracy: 0.4844\n",
      "Epoch 46/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2957 - accuracy: 0.4802 - val_loss: 1.3718 - val_accuracy: 0.4844\n",
      "Epoch 47/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.2776 - accuracy: 0.4856 - val_loss: 1.3706 - val_accuracy: 0.4844\n",
      "Epoch 48/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.2855 - accuracy: 0.4870 - val_loss: 1.3733 - val_accuracy: 0.4844\n",
      "Epoch 49/64\n",
      "46/46 [==============================] - 9s 186ms/step - loss: 1.2896 - accuracy: 0.4952 - val_loss: 1.3739 - val_accuracy: 0.4844\n",
      "Epoch 50/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2931 - accuracy: 0.4679 - val_loss: 1.3742 - val_accuracy: 0.4844\n",
      "Epoch 51/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.2932 - accuracy: 0.4788 - val_loss: 1.3742 - val_accuracy: 0.4844\n",
      "Epoch 52/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2814 - accuracy: 0.4802 - val_loss: 1.3741 - val_accuracy: 0.4844\n",
      "Epoch 53/64\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 1.3204 - accuracy: 0.4596 - val_loss: 1.3732 - val_accuracy: 0.4844\n",
      "Epoch 54/64\n",
      "46/46 [==============================] - 8s 182ms/step - loss: 1.2868 - accuracy: 0.4897 - val_loss: 1.3729 - val_accuracy: 0.4844\n",
      "Epoch 55/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.3042 - accuracy: 0.4747 - val_loss: 1.3742 - val_accuracy: 0.4844\n",
      "Epoch 56/64\n",
      "46/46 [==============================] - 8s 184ms/step - loss: 1.2872 - accuracy: 0.4761 - val_loss: 1.3733 - val_accuracy: 0.4844\n",
      "Epoch 57/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.2726 - accuracy: 0.4651 - val_loss: 1.3728 - val_accuracy: 0.4844\n",
      "Epoch 58/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 9s 187ms/step - loss: 1.2849 - accuracy: 0.4815 - val_loss: 1.3722 - val_accuracy: 0.4844\n",
      "Epoch 59/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.3059 - accuracy: 0.4651 - val_loss: 1.3723 - val_accuracy: 0.4844\n",
      "Epoch 60/64\n",
      "46/46 [==============================] - 9s 185ms/step - loss: 1.2866 - accuracy: 0.4925 - val_loss: 1.3733 - val_accuracy: 0.4844\n",
      "Epoch 61/64\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 1.2564 - accuracy: 0.4706 - val_loss: 1.3725 - val_accuracy: 0.4844\n",
      "Epoch 62/64\n",
      "46/46 [==============================] - 8s 183ms/step - loss: 1.2836 - accuracy: 0.4829 - val_loss: 1.3721 - val_accuracy: 0.4844\n",
      "Epoch 63/64\n",
      "46/46 [==============================] - 8s 185ms/step - loss: 1.3101 - accuracy: 0.4637 - val_loss: 1.3732 - val_accuracy: 0.4844\n",
      "Epoch 64/64\n",
      "46/46 [==============================] - 9s 187ms/step - loss: 1.2833 - accuracy: 0.4761 - val_loss: 1.3731 - val_accuracy: 0.4844\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    f\"{model_name}.h5\", save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=64)\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=64,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=1,\n",
    "            shuffle=False,\n",
    "#             callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ffd11596e381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4549375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = keras.models.load_model('RestNet50-V2_Coronal_SkipCon_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 128s 275ms/step - loss: 8.7462 - accuracy: 0.4527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.746248746687366, 0.4527027]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{model_name}_history.pkl', 'wb') as fh:\n",
    "    pickle.dump(history.history, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
